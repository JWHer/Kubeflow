{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change these to try this notebook out\n",
    "# In \"production\", these will be replaced by the parameters passed to papermill\n",
    "BUCKET = 'cse-linux-kubeflowpipelines-default'\n",
    "PROJECT = 'cse-linux'\n",
    "REGION = 'us'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['TRAIN'] = BUCKET+'/train/'\n",
    "os.environ['DATA'] = BUCKET+'/rawdata'\n",
    "os.environ['MODEL'] = BUCKET+'/model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "WARNING: You do not appear to have access to project [cse-linux] or it does not exist.\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the input data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_BUCKET = \"gs://cse-linux-kubeflowpipelines-default/rawdata/\"\n",
    "#TRAIN_DATA_PATTERN = DATA_BUCKET + \"train*\"\n",
    "#VALID_DATA_PATTERN = DATA_BUCKET + \"test*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cse-linux-kubeflowpipelines-default/rawdata/\n",
      "gs://cse-linux-kubeflowpipelines-default/rawdata/186_Pirates of the Caribbean.csv\n",
      "gs://cse-linux-kubeflowpipelines-default/rawdata/229_Surrogates.csv\n",
      "gs://cse-linux-kubeflowpipelines-default/rawdata/230_Swordfish.csv\n",
      "gs://cse-linux-kubeflowpipelines-default/rawdata/231_Terminator.csv\n",
      "gs://cse-linux-kubeflowpipelines-default/rawdata/51_conan_the_barbarian.csv\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls $DATA_BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.3.1\n"
     ]
    }
   ],
   "source": [
    "import os, json, math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow version \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train/train.py 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['IMAGE_PREFIX'] = \"cse-linux\"\n",
    "os.environ['TRAIN_DIR'] = \"train\"\n",
    "os.environ['PROJECT_ID'] = \"cse-linux\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon   34.3kB\n",
      "Step 1/23 : FROM ubuntu:16.04\n",
      " ---> 9499db781771\n",
      "Step 2/23 : RUN apt-get update\n",
      " ---> Using cache\n",
      " ---> e23217dd7c4b\n",
      "Step 3/23 : RUN apt-get install -y software-properties-common vim\n",
      " ---> Using cache\n",
      " ---> 98af1b4d76ec\n",
      "Step 4/23 : RUN add-apt-repository ppa:deadsnakes/ppa\n",
      " ---> Using cache\n",
      " ---> 98712b2f175e\n",
      "Step 5/23 : RUN apt-get update\n",
      " ---> Using cache\n",
      " ---> 94c7ac45876e\n",
      "Step 6/23 : RUN apt-get install -y build-essential python python-dev python3.6 python3.6-dev python3-pip python3.6-venv\n",
      " ---> Using cache\n",
      " ---> bf3097e869e5\n",
      "Step 7/23 : RUN apt-get install -y git\n",
      " ---> Using cache\n",
      " ---> 20bb6257a069\n",
      "Step 8/23 : RUN python3.6 -m pip install pip --upgrade\n",
      " ---> Using cache\n",
      " ---> 6d2a8a99dd78\n",
      "Step 9/23 : RUN python3.6 -m pip install wheel\n",
      " ---> Using cache\n",
      " ---> d49ff1b94e43\n",
      "Step 10/23 : RUN python3.6 -m pip install --upgrade google-cloud-storage\n",
      " ---> Using cache\n",
      " ---> bfbc53cfadb5\n",
      "Step 11/23 : RUN python3.6 -m pip install --upgrade gcsfs\n",
      " ---> Using cache\n",
      " ---> 6e28facc6e7f\n",
      "Step 12/23 : RUN python3.6 -m pip install --upgrade sklearn\n",
      " ---> Using cache\n",
      " ---> 841999c3f5d2\n",
      "Step 13/23 : RUN python3.6 -m pip install --upgrade argparse\n",
      " ---> Using cache\n",
      " ---> 19691ad43b85\n",
      "Step 14/23 : RUN python3.6 -m pip install --upgrade pandas\n",
      " ---> Using cache\n",
      " ---> 7be28d1ea0f5\n",
      "Step 15/23 : RUN python3.6 -m pip install --upgrade simplejson\n",
      " ---> Using cache\n",
      " ---> 47edeab3a08d\n",
      "Step 16/23 : RUN python3.6 -m pip install --upgrade transformers\n",
      " ---> Using cache\n",
      " ---> 85fea22fc30a\n",
      "Step 17/23 : RUN python3.6 -m pip install --upgrade torch\n",
      " ---> Using cache\n",
      " ---> a05e7d2b2788\n",
      "Step 18/23 : RUN python3.6 -m pip install --upgrade torchtext\n",
      " ---> Using cache\n",
      " ---> 8cd5ce18281b\n",
      "Step 19/23 : ENV PYTHONUNBUFFERED 1\n",
      " ---> Using cache\n",
      " ---> 0bf5bc99b853\n",
      "Step 20/23 : RUN mkdir -p /nlp/src\n",
      " ---> Using cache\n",
      " ---> 03847a64abd7\n",
      "Step 21/23 : COPY . /nlp/src\n",
      " ---> e3e8a3ff711f\n",
      "Step 22/23 : WORKDIR /nlp/src\n",
      " ---> Running in cc6bf24e49db\n",
      "Removing intermediate container cc6bf24e49db\n",
      " ---> 31b818465e33\n",
      "Step 23/23 : ENTRYPOINT [\"python3.6\", \"train.py\"]\n",
      " ---> Running in 3182fa0ab058\n",
      "Removing intermediate container 3182fa0ab058\n",
      " ---> 6112cea825a3\n",
      "Successfully built 6112cea825a3\n",
      "Successfully tagged cse-linux-train:latest\n",
      "The push refers to repository [gcr.io/cse-linux/cse-linux-train]\n",
      "\n",
      "\u001b[1B860a58b5: Preparing \n",
      "\u001b[1Ba8a5e6af: Preparing \n",
      "\u001b[1B30fb4276: Preparing \n",
      "\u001b[1Bc6222617: Preparing \n",
      "\u001b[1Bf829ee56: Preparing \n",
      "\u001b[1B05b30dd5: Preparing \n",
      "\u001b[1Bb55cc07b: Preparing \n",
      "\u001b[1Bebab3ffb: Preparing \n",
      "\u001b[1B79fd190f: Preparing \n",
      "\u001b[1Bffd20357: Preparing \n",
      "\u001b[1B0d7728df: Preparing \n",
      "\u001b[1B1e14d83a: Preparing \n",
      "\u001b[1B61693606: Preparing \n",
      "\u001b[1B6fcebb4f: Preparing \n",
      "\u001b[1Bfe7efbe3: Preparing \n",
      "\u001b[1Bd6c319be: Preparing \n",
      "\u001b[1Bb435b00a: Preparing \n",
      "\u001b[1B4ae21aa9: Preparing \n",
      "\u001b[1B1ddc7399: Preparing \n",
      "\u001b[1B19626b20: Preparing \n",
      "\u001b[1Bc8292d9b: Preparing \n",
      "\u001b[1B74332e2e: Preparing \n",
      "\u001b[23B60a58b5: Pushed lready exists 5kB\u001b[23A\u001b[2K\u001b[22A\u001b[2K\u001b[18A\u001b[2K\u001b[16A\u001b[2K\u001b[14A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2K\u001b[23A\u001b[2Klatest: digest: sha256:3011a7fcfe58dc70b6968a5a6bd333f6f97e3e61f5f635ce3225cdcc0e724533 size: 5157\n"
     ]
    }
   ],
   "source": [
    "!docker build -t $IMAGE_PREFIX-$TRAIN_DIR $TRAIN_DIR/.\n",
    "!docker tag $IMAGE_PREFIX-$TRAIN_DIR:latest gcr.io/$PROJECT_ID/$IMAGE_PREFIX-$TRAIN_DIR:latest\n",
    "!docker push gcr.io/$PROJECT_ID/$IMAGE_PREFIX-$TRAIN_DIR:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File download Started... Wait for the job to complete.\n",
      "Blobs: rawdata/186_Pirates of the Caribbean.csv\n",
      "Blobs: rawdata/229_Surrogates.csv\n",
      "Blobs: rawdata/230_Swordfish.csv\n",
      "Blobs: rawdata/231_Terminator.csv\n",
      "Blobs: rawdata/51_conan_the_barbarian.csv\n",
      "9\n",
      "Making model...\n",
      "/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "No GPU available, using the CPU instead.\n",
      "/usr/local/lib/python3.6/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
      "Wrod Count : 705\n",
      "Num of classes : 8\n",
      "/usr/local/lib/python3.6/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "No accuracy file, we will create one\n",
      "/usr/local/lib/python3.6/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "[Epoch: 1] val loss :  1.58 | val accuracy : 50.54\n",
      "File model.pkl uploaded\n",
      "\n",
      "Writing matcis file: /mlpipeline-metrics.json\n",
      "[Epoch: 2] val loss :  1.22 | val accuracy : 56.65\n",
      "File model.pkl uploaded\n",
      "\n",
      "Writing matcis file: /mlpipeline-metrics.json\n",
      "[Epoch: 3] val loss :  1.02 | val accuracy : 63.64\n",
      "File model.pkl uploaded\n",
      "\n",
      "Writing matcis file: /mlpipeline-metrics.json\n",
      "[Epoch: 4] val loss :  0.98 | val accuracy : 64.65\n",
      "File model.pkl uploaded\n",
      "\n",
      "Writing matcis file: /mlpipeline-metrics.json\n",
      "[Epoch: 5] val loss :  0.92 | val accuracy : 65.79\n",
      "File model.pkl uploaded\n",
      "\n",
      "Writing matcis file: /mlpipeline-metrics.json\n",
      "[Epoch: 6] val loss :  0.91 | val accuracy : 66.19\n",
      "File model.pkl uploaded\n",
      "\n",
      "Writing matcis file: /mlpipeline-metrics.json\n",
      "[Epoch: 7] val loss :  0.92 | val accuracy : 65.03\n",
      "[Epoch: 8] val loss :  0.92 | val accuracy : 65.86\n",
      "[Epoch: 9] val loss :  0.94 | val accuracy : 64.11\n",
      "[Epoch: 10] val loss :  0.92 | val accuracy : 65.67\n",
      "Loss:  0.91 | ACC: 66.19\n"
     ]
    }
   ],
   "source": [
    "!docker run gcr.io/$PROJECT_ID/$IMAGE_PREFIX-$TRAIN_DIR:latest \\\n",
    "--csv_uri $BUCKET \\\n",
    "--checkpoint_uri gs://$MODEL/model.pkl \\\n",
    "--acc_uri gs://$BUCKET/latestacc/acc.csv \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfp_pipline.ipynb\n",
      "pipeline.ipynb\n",
      "setup.py\n",
      "template.ipynb\n",
      "train/\n",
      "train/Dockerfile\n",
      "train/.ipynb_checkpoints/\n",
      "train/.ipynb_checkpoints/Dockerfile-checkpoint\n",
      "train/.ipynb_checkpoints/train-checkpoint.py\n",
      "train/.ipynb_checkpoints/train-Copy1-checkpoint.py\n",
      "train/train-Copy1.py\n",
      "train/train.py\n",
      "train.tar.gz\n",
      "train_pipelines.zip\n",
      "Copying file://train.tar.gz [Content-Type=application/x-tar]...\n",
      "/ [1 files][ 21.6 KiB/ 21.6 KiB]                                                \n",
      "Operation completed over 1 objects/21.6 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!tar zcvf train.tar.gz *\n",
    "!gsutil cp train.tar.gz gs://cse-linux-kubeflowpipelines-default/train"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
